{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install accelerate>=0.26.0\n",
    "%pip install --upgrade jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/tmp/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/tmp/huggingface\"\n",
    "\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct-1M\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=\"/tmp/huggingface\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"/tmp/huggingface\")\n",
    "\n",
    "prompt = '''You are given a passage from a movie script. Return all spoken dialogue. This may be in the form of explicit dialogue, or as a person speaking in stage directions or in any other sections of the script. Do not return any addition content aside from the explicit lines from the transcript. Do not number the output. \n",
    "\n",
    "MS -- Dorothy and Toto -- she tosses him a piece of the\n",
    "cruller -- Toto eats it -- Dorothy speaks as she walks\n",
    "forward -- she sings -- leans against haystack -- then walks\n",
    "over near rake -- CAMERA PANS right --\n",
    "\n",
    "                    DOROTHY (CONT'D)\n",
    "          Do you suppose there is such a place,\n",
    "          Toto? There must be. It's not a place\n",
    "          you can get to by a boat or a train.\n",
    "          It's far, far away -- behind the moon --\n",
    "          beyond the rain --\n",
    "\n",
    "                    DOROTHY (CONT'D)\n",
    "              (sings)\n",
    "          Somewhere, over the rainbow, way up high,\n",
    "          There's a land that I heard of once in a\n",
    "          lullaby.\n",
    "\n",
    "Somewhere, over the rainbow, skies are blue, And the dreams\n",
    "that you dare to dream really do.... CS -- Toto by wheel of\n",
    "rake -- listening to song -- DOROTHY o.s. (sings) ...come\n",
    "true.... MCS -- Dorothy singing -- swings on wheel of rake --\n",
    "then walks forward around wheel -- Toto jumps up onto seat of\n",
    "rake -- Dorothy pets him -- sits on front of rake -- CAMERA\n",
    "PULLS back -- Dorothy finishes song --\n",
    "\n",
    "                    DOROTHY (CONT'D)\n",
    "              (sings)\n",
    "          ...Someday I'll wish upon a star And wake\n",
    "          up where the clouds are far behind me.\n",
    "\n",
    "Where troubles melt like lemon drops, Away above the chimney\n",
    "tops, That's where you'll find me. Somewhere, over the\n",
    "rainbow, bluebirds fly. Birds fly over the rainbow, Why then -\n",
    "- oh, why can't I? If happy little bluebirds fly Beyond the\n",
    "rainbow Why, oh, why can't I? LS -- Miss Gulch rides along\n",
    "country road on bicycle -- CAMERA PANS to right with her --\n",
    "LS -- Miss Gulch rides forward to front of Gale's home --\n",
    "stops and gets off her bicycle as Uncle Henry comes forward --\n",
    "\n",
    "'''\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
