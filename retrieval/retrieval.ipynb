{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain faiss-cpu tiktoken\n",
    "%pip install sentence-transformers\n",
    "%pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She isn't coming yet, Toto. Did she hurt you? She tried to, didn't she? Come on - we'll go tell Uncle Henry and Auntie Em. Come on, Toto.\n",
      "Aunt Em!\n",
      "Dorothy!\n",
      "AUNT EM\n",
      "Fifty-seven, fifty-eight --\n",
      "Dorothy, please! We're trying to count!\n",
      "Fifty-eight--\n",
      "Oh, but Aunt Em, she hit him over the --  \n",
      "\n",
      "Don't bother us now, honey -- this old incubator's gone bad, and we're likely to lose a lot of our chicks.\n",
      "\n",
      "Oh -- oh, the poor little things. Oh, but Aunt Em, Miss Gulch hit Toto right over the back with a rake just because she says he gets in her garden and chases her nasty old cat every day.\n",
      "\n",
      "Seventy --    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS \n",
    "\n",
    "\n",
    "file_path = \"output.txt\"\n",
    "\n",
    "loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(documents[0].page_content[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3059\n"
     ]
    }
   ],
   "source": [
    "script = documents[0].page_content\n",
    "add = False\n",
    "scriptDict = {}\n",
    "for i, line in enumerate(script.splitlines()):\n",
    "    scriptDict[i] = line.strip() + \" \"        \n",
    "print(len(scriptDict))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device':'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,    \n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open ('combined_scenes.json', 'r') as file:\n",
    "    scenes = json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_text = []\n",
    "transcript_vectors = []\n",
    "\n",
    "for i in range(len(scriptDict)):\n",
    "    transcript_text.append(scriptDict[i])\n",
    "    transcript_vectors.append(embeddings.embed_query(scriptDict[i]))\n",
    "    \n",
    "scene_vectors = []\n",
    "for i, scene in enumerate(scenes):\n",
    "    scene_vectors.append(embeddings.embed_query(scene['subtitle']))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_arr = []\n",
    "for i, scene in enumerate(scenes):\n",
    "    scene_arr.append(scene['subtitle'])\n",
    "\n",
    "scene_text = \" \".join(scene_arr).strip()\n",
    "trans_text = \" \".join(transcript_text).strip()\n",
    "\n",
    "scene_text = scene_text.replace(\"\\\\\", \"\")\n",
    "trans_text = trans_text.replace(\"\\\\\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trans_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_transcript_text = transcript_text.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaushik's Thoughts\n",
    "Old Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "context_length = 10\n",
    "res = {}\n",
    "cache = {}\n",
    "\n",
    "for i, scene_vector in enumerate(scene_vectors):\n",
    "    print(\"i: \" + str(i))\n",
    "    print(\"Scene: \" + scenes[i]['subtitle'])\n",
    "    scene_norm = norm(scene_vector)\n",
    "    best_similarity = 0.0\n",
    "    start = None\n",
    "    end = None\n",
    "    res[i] = []\n",
    "    \n",
    "    j = 0\n",
    "    while j < len(transcript_vectors):\n",
    "        print(\"j: \" + str(j))\n",
    "        if start is None:\n",
    "            start = j\n",
    "            end = j\n",
    "        lines = transcript_text[start:j + 1]\n",
    "        key = (start, j + 1)\n",
    "        if key in cache:\n",
    "            possible_vector = cache[key]\n",
    "        else:\n",
    "            possible_text = \" \".join(lines).strip()\n",
    "            print(\"possible text:\" + possible_text)\n",
    "            possible_vector = embeddings.embed_query(possible_text)\n",
    "            cache[key] = possible_vector\n",
    "        \n",
    "        possible_norm = norm(possible_vector)\n",
    "        if scene_norm == 0.0 or possible_norm == 0.0:\n",
    "            current_similarity = 0.0\n",
    "        else:\n",
    "            current_similarity = dot(scene_vector, possible_vector) / (scene_norm * possible_norm)\n",
    "            print(\"Current similarity: \" + str(current_similarity))\n",
    "        \n",
    "        tol = 0.01 if best_similarity > 0.9 else 0.05\n",
    "        \n",
    "        if current_similarity + tol >= best_similarity:\n",
    "            best_similarity = current_similarity\n",
    "            print(\"Best similarity: \" + str(best_similarity))\n",
    "            end = j\n",
    "            j += 1 \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if start is not None and end is not None:\n",
    "        final_text_list = transcript_text[start:end + 1]\n",
    "        final_text = \" \".join(final_text_list).strip()\n",
    "        \n",
    "        contextual_start = max(0, start - context_length)\n",
    "        contextual_end = min(len(transcript_text) - 1, end + context_length)\n",
    "        \n",
    "        context_list = transcript_text[contextual_start:contextual_end + 1]\n",
    "        context_text = \" \".join(context_list).strip()\n",
    "        \n",
    "        result = {\n",
    "            \"chunk start\": start,\n",
    "            \"chunk end\": end,\n",
    "            \"best similarity\": best_similarity,\n",
    "            \"subtitle\": scenes[i]['subtitle'],\n",
    "            \"text\": final_text,\n",
    "            \"context\": context_text,\n",
    "            \"range\": (contextual_start, contextual_end)\n",
    "        }\n",
    "        \n",
    "        res[i].append(result)\n",
    "        transcript_vectors = transcript_vectors[end + 1:]\n",
    "        transcript_text = transcript_text[end + 1:]\n",
    "        cache = {}\n",
    "        j = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaushik's Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Derivative Similarity Approach\n",
    "\n",
    "T(s) = k * (1-s) ** a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_text = original_transcript_text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from fuzzywuzzy import fuzz\n",
    "import statistics\n",
    "\n",
    "context_length = 10\n",
    "res = {}\n",
    "cache = {}\n",
    "\n",
    "k = 0.9\n",
    "alpha = 1.7\n",
    "min_allowed_increment = 0.0005\n",
    "patience = 20\n",
    "\n",
    "window_length = 6\n",
    "fuzzy_threshold = 75\n",
    "\n",
    "subtitle_scores = []\n",
    "for i, scene_vector in enumerate(scene_vectors):\n",
    "    print(\"i: \" + str(i))\n",
    "    print(\"Scene: \" + scenes[i]['subtitle'])\n",
    "    scene_norm = norm(scene_vector)\n",
    "    best_similarity = 0.0\n",
    "    start = None\n",
    "    end = None\n",
    "    res[i] = []\n",
    "    prev_similarity = 0.0\n",
    "    current_similarity = 0.0\n",
    "    no_improvement = 0\n",
    "    \n",
    "    subtitle_start = \" \".join(scenes[i]['subtitle'].split()[:10])\n",
    "    found_start = None\n",
    "    for j in range(0, len(transcript_text) - window_length + 1):\n",
    "        window_text = \" \".join(transcript_text[j:j+window_length])\n",
    "        ratio = fuzz.partial_ratio(subtitle_start.lower(), window_text.lower())\n",
    "        if ratio >= fuzzy_threshold:\n",
    "            found_start = j\n",
    "            break  \n",
    "    if found_start is not None:\n",
    "        start = found_start\n",
    "        j = start   \n",
    "        print(\"fuzzy\")\n",
    "    else:\n",
    "        start = 0\n",
    "        j = 0\n",
    "        print(\"No fuzzy\")\n",
    "    \n",
    "    while j < len(transcript_vectors):\n",
    "        print(\"j: \" + str(j))\n",
    "        lines = transcript_text[start:j + 1]\n",
    "        key = (start, j + 1)\n",
    "        if key in cache:\n",
    "            possible_vector = cache[key]\n",
    "        else:\n",
    "            possible_text = \" \".join(lines).strip()\n",
    "            print(\"possible text: \" + possible_text)\n",
    "            possible_vector = embeddings.embed_query(possible_text)\n",
    "            cache[key] = possible_vector\n",
    "        \n",
    "        possible_norm = norm(possible_vector)\n",
    "        if scene_norm == 0.0 or possible_norm == 0.0:\n",
    "            prev_similarity = current_similarity\n",
    "            current_similarity = 0.0\n",
    "        else:\n",
    "            prev_similarity = current_similarity\n",
    "            current_similarity = dot(scene_vector, possible_vector) / (scene_norm * possible_norm)\n",
    "            print(\"Current similarity: \" + str(current_similarity))\n",
    "        \n",
    "        tolerance = k * (1 - best_similarity) ** alpha\n",
    "        delta = current_similarity - prev_similarity\n",
    "        \n",
    "        if delta < 0 and abs(delta) > tolerance:\n",
    "            break\n",
    "        else:\n",
    "            if delta < min_allowed_increment and transcript_text[j] != \"\":\n",
    "                no_improvement += 1\n",
    "            else:\n",
    "                no_improvement = 0\n",
    "            if no_improvement > patience:\n",
    "                break\n",
    "            \n",
    "            if current_similarity > best_similarity:\n",
    "                best_similarity = current_similarity\n",
    "                end = j\n",
    "            j += 1\n",
    "    #go through possible_text and delete from the start line by line to see if similarity can get better. if it gets worse (tolerance), leave. if it gets better, use new\n",
    "    if end is not None:\n",
    "        for k in range(start, end):\n",
    "            lines = transcript_text[k:end + 1]\n",
    "            lines_vector = embeddings.embed_query(\" \".join(lines).strip())\n",
    "            lines_norm = norm(lines_vector)\n",
    "            ratio = dot(scene_vector, lines_vector) / (scene_norm * lines_norm)\n",
    "            if ratio > best_similarity:\n",
    "                best_similarity = ratio\n",
    "                start = k\n",
    "            elif best_similarity - ratio > tolerance:\n",
    "                break\n",
    "    \n",
    "            \n",
    "    if start is not None and end is not None:\n",
    "        final_text_list = transcript_text[start:end + 1]\n",
    "        final_text = \" \".join(final_text_list).strip()\n",
    "        \n",
    "        contextual_start = max(0, start - context_length)\n",
    "        contextual_end = min(len(transcript_text) - 1, end + context_length)\n",
    "        \n",
    "        context_list = transcript_text[contextual_start:contextual_end + 1]\n",
    "        context_text = \" \".join(context_list).strip()\n",
    "        \n",
    "        result = {\n",
    "            \"chunk start\": start,\n",
    "            \"chunk end\": end,\n",
    "            \"best similarity\": best_similarity,\n",
    "            \"subtitle\": scenes[i]['subtitle'],\n",
    "            \"text\": final_text,\n",
    "            \"context\": context_text,\n",
    "            \"range\": (contextual_start, contextual_end)\n",
    "        }\n",
    "        \n",
    "        res[i].append(result)\n",
    "        transcript_vectors = transcript_vectors[max(end - 30, 0):]\n",
    "        transcript_text = transcript_text[max(end - 30, 0):]\n",
    "        cache = {}\n",
    "        subtitle_scores.append(best_similarity)\n",
    "        j = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitle_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subtitle_scores:\n",
    "    avg_score = statistics.mean(subtitle_scores)\n",
    "    median_score = statistics.median(subtitle_scores)\n",
    "    # Use pstdev for population standard deviation (all scenes considered), or stdev for sample std dev\n",
    "    stdev_score = statistics.pstdev(subtitle_scores) if len(subtitle_scores) > 1 else 0.0\n",
    "\n",
    "    # Calculate how many scenes exceed the given thresholds\n",
    "    total_scenes = len(subtitle_scores)\n",
    "    above_0_7 = sum(1 for s in subtitle_scores if s >= 0.7)\n",
    "    above_0_8 = sum(1 for s in subtitle_scores if s >= 0.8)\n",
    "    perc_above_0_7 = (above_0_7 / total_scenes) * 100\n",
    "    perc_above_0_8 = (above_0_8 / total_scenes) * 100\n",
    "    \n",
    "    above_0_5 = sum(1 for s in subtitle_scores if s >= 0.5)\n",
    "    above_0_6 = sum(1 for s in subtitle_scores if s >= 0.58)\n",
    "    perc_above_0_5 = (above_0_5 / total_scenes) * 100\n",
    "    perc_above_0_6 = (above_0_6 / total_scenes) * 100\n",
    "\n",
    "    # Print a clear performance summary\n",
    "    print(\"\\n=== Performance Summary ===\")\n",
    "    print(f\"Total scenes processed: {total_scenes}\")\n",
    "    print(f\"Average similarity score: {avg_score:.3f}\")\n",
    "    print(f\"Median similarity score: {median_score:.3f}\")\n",
    "    print(f\"Standard deviation of similarity scores: {stdev_score:.3f}\")\n",
    "    print(f\"Scenes with similarity >= 0.5: {above_0_5}/{total_scenes} \" \n",
    "          f\"({perc_above_0_5:.1f}%)\")\n",
    "    print(f\"Scenes with similarity >= 0.6: {above_0_6}/{total_scenes} \" \n",
    "          f\"({perc_above_0_6:.1f}%)\")\n",
    "    print(f\"Scenes with similarity >= 0.7: {above_0_7}/{total_scenes} \" \n",
    "          f\"({perc_above_0_7:.1f}%)\")\n",
    "    print(f\"Scenes with similarity >= 0.8: {above_0_8}/{total_scenes} \" \n",
    "          f\"({perc_above_0_8:.1f}%)\")\n",
    "    print(\"===========================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "s1 = ''' \n",
    "        Someplace where there isn't any trouble. Do you suppose there is such a place, Toto? There must be. It's not a place you can get to by a boat or a train. It's far, far away. Behind the moon... ...beyond the rain.... [SINGlNG] Somewhere over the rainbow Way up high There's a land that l heard of Once in a lullaby Somewhere over the rainbow Skies are blue And the dreams that you dare to dream Really do come true\n",
    "'''\n",
    "s2 = '''\n",
    "DOROTHY  Some place where there isn't any trouble.        (CONTINUED)    8.  CONTINUED: (7)      MS -- Dorothy and Toto -- she tosses him a piece of the  cruller -- Toto eats it -- Dorothy speaks as she walks  forward -- she sings -- leans against haystack -- then walks  over near rake -- CAMERA PANS right --    DOROTHY (CONT'D)  Do you suppose there is such a place,  Toto? There must be. It's not a place  you can get to by a boat or a train.  It's far, far away -- behind the moon --  beyond the rain --    DOROTHY (CONT'D)  (sings)  Somewhere, over the rainbow, way up high,  There's a land that I heard of once in a  lullaby.    Somewhere, over the rainbow, skies are blue, And the dreams  that you dare to dream really do.... CS -- Toto by wheel of  rake -- listening to song -- DOROTHY o.s. (sings) ...come  true.... MCS -- Dorothy singing -- swings on wheel of rake --  then walks forward around wheel -- Toto jumps up onto seat of  rake -- Dorothy pets him -- sits on front of rake -- CAMERA  PULLS back -- Dorothy finishes song --    DOROTHY (CONT'D)  (sings)  ...Someday I'll wish upon a star And wake  up where the clouds are far behind me.    Where troubles melt like lemon drops, Away above the chimney  tops, That's where you'll find me. Somewhere, over the  rainbow, bluebirds fly. Birds fly over the rainbow, Why then -  - oh, why can't I? If happy little bluebirds fly Beyond the  rainbow Why, oh, why can't I? LS -- Miss Gulch rides along  country road on bicycle -- CAMERA PANS to right with her --  LS -- Miss Gulch rides forward to front of Gale's home --  stops and gets off her bicycle as Uncle Henry comes forward\n",
    "'''\n",
    "\n",
    "\n",
    "one = embeddings.embed_query(s1)\n",
    "two = embeddings.embed_query(s2)\n",
    "dp = (dot(one, two))\n",
    "nm = norm(one) * norm(two)\n",
    "ratio = dp / nm\n",
    "\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced Optimal Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Split text into tokens (words), ignoring punctuation but keeping apostrophes in words.\"\"\"\n",
    "    import re\n",
    "    # Keep letters, numbers, and apostrophes as part of words\n",
    "    tokens = re.findall(r\"[A-Za-z0-9']+\", text)\n",
    "    return tokens\n",
    "\n",
    "def align_subtitle_transcript(subtitle_text, transcript_text):\n",
    "    \"\"\"Align subtitle text with transcript text using DP. Returns list of (subtitle_word, transcript_word) pairs.\"\"\"\n",
    "    # Tokenize both texts\n",
    "    s_words = tokenize(subtitle_text)\n",
    "    t_words = tokenize(transcript_text)\n",
    "    n, m = len(s_words), len(t_words)\n",
    "    # DP table and backpointer initialization\n",
    "    # dp[i][j] = minimum alignment cost for s_words[:i] vs t_words[:j]\n",
    "    dp = [[0] * (m+1) for _ in range(n+1)]\n",
    "    backptr = [[None] * (m+1) for _ in range(n+1)]\n",
    "    # Initialize base cases: align empty sequence with prefixes (cost = j or i gaps)\n",
    "    for i in range(1, n+1):\n",
    "        dp[i][0] = i  # i deletions (skip all i subtitle words)\n",
    "        backptr[i][0] = (i-1, 0, 'up')  # came from above (skip subtitle word)\n",
    "    for j in range(1, m+1):\n",
    "        dp[0][j] = j  # j insertions (skip all j transcript words)\n",
    "        backptr[0][j] = (0, j-1, 'left')  # came from left (skip transcript word)\n",
    "    # Fill DP table\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            # Cost for substituting or matching s_words[i-1] with t_words[j-1]\n",
    "            if s_words[i-1].lower() == t_words[j-1].lower():\n",
    "                match_cost = 0  # words match\n",
    "            else:\n",
    "                match_cost = 1  # words differ (substitution cost)\n",
    "            # Compute costs for three possibilities:\n",
    "            # 1. Match/Substitute s_words[i-1] with t_words[j-1]\n",
    "            cost_diag = dp[i-1][j-1] + match_cost\n",
    "            # 2. Skip s_words[i-1] (align it to a gap)\n",
    "            cost_up = dp[i-1][j] + 1  # gap cost = 1\n",
    "            # 3. Skip t_words[j-1] (align it to a gap)\n",
    "            cost_left = dp[i][j-1] + 1  # gap cost = 1\n",
    "            # Choose min cost option\n",
    "            min_cost = cost_diag\n",
    "            direction = 'diag'\n",
    "            if cost_up < min_cost:\n",
    "                min_cost = cost_up\n",
    "                direction = 'up'\n",
    "            if cost_left < min_cost:\n",
    "                min_cost = cost_left\n",
    "                direction = 'left'\n",
    "            dp[i][j] = min_cost\n",
    "            # Record backpointer for reconstructing alignment\n",
    "            if direction == 'diag':\n",
    "                backptr[i][j] = (i-1, j-1, 'diag')\n",
    "            elif direction == 'up':\n",
    "                backptr[i][j] = (i-1, j, 'up')\n",
    "            else:  # 'left'\n",
    "                backptr[i][j] = (i, j-1, 'left')\n",
    "    # Backtrack from dp[n][m] to get alignment\n",
    "    alignment = []\n",
    "    i, j = n, m\n",
    "    while i > 0 or j > 0:\n",
    "        prev_i, prev_j, direction = backptr[i][j]\n",
    "        if direction == 'diag':\n",
    "            # Word from subtitle aligned to word from transcript (match or substitution)\n",
    "            alignment.append((s_words[i-1], t_words[j-1]))\n",
    "        elif direction == 'up':\n",
    "            # Subtitle word aligned to nothing (it was skipped)\n",
    "            alignment.append((s_words[i-1], None))\n",
    "        elif direction == 'left':\n",
    "            # Transcript word aligned to nothing (skipped on transcript side)\n",
    "            alignment.append((None, t_words[j-1]))\n",
    "        i, j = prev_i, prev_j\n",
    "    alignment.reverse()  # reverse to get from start to end\n",
    "    return alignment\n",
    "\n",
    "# Example usage:\n",
    "subtitle = scene_text\n",
    "transcript = trans_text\n",
    "alignment = align_subtitle_transcript(subtitle, transcript)\n",
    "count = 0\n",
    "for pair in alignment:\n",
    "    if pair[0] is None or pair[1] is None:\n",
    "        count += 1\n",
    "    print(pair)\n",
    "    \n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alignment)\n",
    "count = 0\n",
    "for pair in alignment:\n",
    "    if pair[0] is None or pair[1] is None:\n",
    "        count += 1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
